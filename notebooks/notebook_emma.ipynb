{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! codecarbon init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset_generator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 00:03:50] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 00:03:50] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 00:03:50] No GPU found.\n",
      "[codecarbon INFO @ 00:03:50] [setup] CPU Tracking...\n",
      "[codecarbon INFO @ 00:03:50] Tracking Intel CPU via Power Gadget\n",
      "[codecarbon INFO @ 00:03:54] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 00:03:54]   Platform system: macOS-12.5.1-x86_64-i386-64bit\n",
      "[codecarbon INFO @ 00:03:54]   Python version: 3.9.15\n",
      "[codecarbon INFO @ 00:03:54]   Available RAM : 8.000 GB\n",
      "[codecarbon INFO @ 00:03:54]   CPU count: 4\n",
      "[codecarbon INFO @ 00:03:54]   CPU model: Intel(R) Core(TM) i5-6267U CPU @ 2.90GHz\n",
      "[codecarbon INFO @ 00:03:54]   GPU count: None\n",
      "[codecarbon INFO @ 00:03:54]   GPU model: None\n",
      "  0%|          | 0/78 [00:00<?, ?it/s][codecarbon INFO @ 00:03:57] Energy consumed for RAM : 0.000000 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:03:59] Energy consumed for all CPUs : 0.000001 kWh. All CPUs Power : 13.618166666666665 W\n",
      "[codecarbon INFO @ 00:04:00] 0.000001 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:04:02] Already started tracking\n",
      "[codecarbon INFO @ 00:04:04] Energy consumed for RAM : 0.000003 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:04:05] Energy consumed for all CPUs : 0.000015 kWh. All CPUs Power : 14.187666666666672 W\n",
      "[codecarbon INFO @ 00:04:06] 0.000018 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:04:08] Already started tracking\n",
      "[codecarbon WARNING @ 00:04:42] Background scheduler didn't run for a long period (35s), results might be inaccurate\n",
      "[codecarbon INFO @ 00:04:42] Energy consumed for RAM : 0.000033 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:04:44] Energy consumed for all CPUs : 0.000149 kWh. All CPUs Power : 13.400333333333334 W\n",
      "[codecarbon INFO @ 00:04:45] 0.000182 kWh of electricity used since the begining.\n",
      "  1%|▏         | 1/78 [00:50<1:04:46, 50.47s/it][codecarbon WARNING @ 00:04:47] Already started tracking\n",
      "[codecarbon INFO @ 00:04:47] Energy consumed for RAM : 0.000035 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:04:49] Energy consumed for all CPUs : 0.000155 kWh. All CPUs Power : 11.639583333333334 W\n",
      "[codecarbon INFO @ 00:04:50] 0.000190 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:04:52] Already started tracking\n",
      "[codecarbon INFO @ 00:04:52] Energy consumed for RAM : 0.000037 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:04:54] Energy consumed for all CPUs : 0.000163 kWh. All CPUs Power : 13.81491666666667 W\n",
      "[codecarbon INFO @ 00:04:55] 0.000200 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:04:57] Already started tracking\n",
      "[codecarbon INFO @ 00:05:06] Energy consumed for RAM : 0.000046 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:05:08] Energy consumed for all CPUs : 0.000204 kWh. All CPUs Power : 13.08 W\n",
      "[codecarbon INFO @ 00:05:09] 0.000250 kWh of electricity used since the begining.\n",
      "  3%|▎         | 2/78 [01:14<44:04, 34.79s/it]  [codecarbon WARNING @ 00:05:11] Already started tracking\n",
      "[codecarbon INFO @ 00:05:11] Energy consumed for RAM : 0.000048 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:05:13] Energy consumed for all CPUs : 0.000212 kWh. All CPUs Power : 13.287749999999997 W\n",
      "[codecarbon INFO @ 00:05:14] 0.000260 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:05:16] Already started tracking\n",
      "[codecarbon INFO @ 00:05:16] Energy consumed for RAM : 0.000049 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:05:17] Energy consumed for all CPUs : 0.000219 kWh. All CPUs Power : 13.448083333333335 W\n",
      "[codecarbon INFO @ 00:05:19] 0.000269 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:05:21] Already started tracking\n",
      "[codecarbon INFO @ 00:05:21] Energy consumed for RAM : 0.000051 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:05:22] Energy consumed for all CPUs : 0.000226 kWh. All CPUs Power : 11.50925 W\n",
      "[codecarbon INFO @ 00:05:24] 0.000277 kWh of electricity used since the begining.\n",
      "  4%|▍         | 3/78 [01:28<31:53, 25.51s/it][codecarbon WARNING @ 00:05:26] Already started tracking\n",
      "[codecarbon INFO @ 00:05:26] Energy consumed for RAM : 0.000053 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:05:27] Energy consumed for all CPUs : 0.000233 kWh. All CPUs Power : 11.411833333333332 W\n",
      "[codecarbon INFO @ 00:05:28] 0.000286 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:05:30] Already started tracking\n",
      "[codecarbon INFO @ 00:05:38] Energy consumed for RAM : 0.000061 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:05:39] Energy consumed for all CPUs : 0.000261 kWh. All CPUs Power : 10.932166666666669 W\n",
      "[codecarbon INFO @ 00:05:41] 0.000322 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:05:43] Already started tracking\n",
      "[codecarbon WARNING @ 00:07:58] Background scheduler didn't run for a long period (137s), results might be inaccurate\n",
      "[codecarbon INFO @ 00:07:58] Energy consumed for RAM : 0.000175 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:08:00] Energy consumed for all CPUs : 0.000520 kWh. All CPUs Power : 6.7902499999999995 W\n",
      "[codecarbon INFO @ 00:08:01] 0.000695 kWh of electricity used since the begining.\n",
      "  5%|▌         | 4/78 [04:06<1:35:41, 77.58s/it][codecarbon WARNING @ 00:08:03] Already started tracking\n",
      "[codecarbon WARNING @ 00:08:03] Already started tracking\n",
      "[codecarbon WARNING @ 00:08:03] Already started tracking\n",
      "[codecarbon WARNING @ 00:08:03] Already started tracking\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "[codecarbon INFO @ 00:08:03] Energy consumed for RAM : 0.000177 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:08:05] Energy consumed for all CPUs : 0.000525 kWh. All CPUs Power : 7.463 W\n",
      "[codecarbon INFO @ 00:08:06] 0.000702 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:08:08] Already started tracking\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "[codecarbon INFO @ 00:08:08] Energy consumed for RAM : 0.000179 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:08:10] Energy consumed for all CPUs : 0.000533 kWh. All CPUs Power : 13.08775 W\n",
      "[codecarbon INFO @ 00:08:11] 0.000712 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:08:13] Already started tracking\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "[codecarbon INFO @ 00:08:23] Energy consumed for RAM : 0.000189 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:08:24] Energy consumed for all CPUs : 0.000571 kWh. All CPUs Power : 11.434333333333333 W\n",
      "[codecarbon INFO @ 00:08:26] 0.000760 kWh of electricity used since the begining.\n",
      " 10%|█         | 8/78 [04:31<32:49, 28.14s/it]  [codecarbon WARNING @ 00:08:28] Already started tracking\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "[codecarbon INFO @ 00:08:28] Energy consumed for RAM : 0.000191 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:08:29] Energy consumed for all CPUs : 0.000579 kWh. All CPUs Power : 13.010833333333332 W\n",
      "[codecarbon INFO @ 00:08:31] 0.000770 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:08:33] Already started tracking\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 125 iterations, i.e. alpha=6.755e-02, with an active set of 99 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "[codecarbon INFO @ 00:08:33] Energy consumed for RAM : 0.000192 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:08:34] Energy consumed for all CPUs : 0.000587 kWh. All CPUs Power : 13.089083333333335 W\n",
      "[codecarbon INFO @ 00:08:36] 0.000779 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:08:38] Already started tracking\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "[codecarbon WARNING @ 00:09:06] Background scheduler didn't run for a long period (30s), results might be inaccurate\n",
      "[codecarbon INFO @ 00:09:06] Energy consumed for RAM : 0.000218 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:09:07] Energy consumed for all CPUs : 0.000681 kWh. All CPUs Power : 11.263333333333334 W\n",
      "[codecarbon INFO @ 00:09:09] 0.000899 kWh of electricity used since the begining.\n",
      " 12%|█▏        | 9/78 [05:13<35:42, 31.05s/it][codecarbon WARNING @ 00:09:11] Already started tracking\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LarsCV())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "[codecarbon INFO @ 00:09:11] Energy consumed for RAM : 0.000219 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:09:12] Energy consumed for all CPUs : 0.000688 kWh. All CPUs Power : 11.214166666666669 W\n",
      "[codecarbon INFO @ 00:09:14] 0.000907 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:09:16] Already started tracking\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LarsCV())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=6.638e+00, with an active set of 80 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=6.431e+00, with an active set of 80 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=5.073e+00, with an active set of 80 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=4.974e+00, with an active set of 80 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=3.761e+00, with an active set of 80 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=3.281e+00, with an active set of 80 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=3.191e+00, with an active set of 80 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=3.100e+00, with an active set of 80 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=3.055e+00, with an active set of 80 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=2.904e+00, with an active set of 80 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=2.604e+00, with an active set of 80 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=2.504e+00, with an active set of 80 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=2.361e+00, with an active set of 80 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=2.307e+00, with an active set of 80 regressors, and the smallest cholesky pivot element being 7.743e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=1.150e+00, with an active set of 80 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=7.167e-01, with an active set of 80 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=6.172e-01, with an active set of 80 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=5.872e-01, with an active set of 80 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=8.487e-02, with an active set of 80 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=1.409e-02, with an active set of 80 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 106 iterations, i.e. alpha=1.160e-02, with an active set of 80 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 106 iterations, i.e. alpha=8.207e-03, with an active set of 80 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 108 iterations, i.e. alpha=8.528e-03, with an active set of 81 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 108 iterations, i.e. alpha=7.786e-03, with an active set of 81 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 108 iterations, i.e. alpha=7.096e-03, with an active set of 81 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 108 iterations, i.e. alpha=6.537e-03, with an active set of 81 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 108 iterations, i.e. alpha=6.175e-03, with an active set of 81 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 108 iterations, i.e. alpha=5.717e-03, with an active set of 81 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 108 iterations, i.e. alpha=5.082e-03, with an active set of 81 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 108 iterations, i.e. alpha=4.560e-03, with an active set of 81 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 108 iterations, i.e. alpha=3.673e-03, with an active set of 81 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 108 iterations, i.e. alpha=3.507e-03, with an active set of 81 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 108 iterations, i.e. alpha=3.363e-03, with an active set of 81 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 108 iterations, i.e. alpha=2.822e-03, with an active set of 81 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 108 iterations, i.e. alpha=2.590e-03, with an active set of 81 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 108 iterations, i.e. alpha=1.790e-03, with an active set of 81 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 108 iterations, i.e. alpha=1.195e-03, with an active set of 81 regressors, and the smallest cholesky pivot element being 5.373e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 108 iterations, i.e. alpha=7.538e-04, with an active set of 81 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 108 iterations, i.e. alpha=3.389e-04, with an active set of 81 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 108 iterations, i.e. alpha=1.695e-04, with an active set of 81 regressors, and the smallest cholesky pivot element being 5.162e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:652: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 108 iterations, i.e. alpha=8.698e-05, with an active set of 81 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "[codecarbon INFO @ 00:09:17] Energy consumed for RAM : 0.000222 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:09:18] Energy consumed for all CPUs : 0.000697 kWh. All CPUs Power : 11.302 W\n",
      "[codecarbon INFO @ 00:09:19] 0.000919 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:09:21] Already started tracking\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LarsCV())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "[codecarbon WARNING @ 00:10:02] Background scheduler didn't run for a long period (42s), results might be inaccurate\n",
      "[codecarbon INFO @ 00:10:02] Energy consumed for RAM : 0.000257 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:10:03] Energy consumed for all CPUs : 0.000774 kWh. All CPUs Power : 6.468333333333333 W\n",
      "[codecarbon INFO @ 00:10:05] 0.001031 kWh of electricity used since the begining.\n",
      " 13%|█▎        | 10/78 [06:09<41:26, 36.57s/it][codecarbon WARNING @ 00:10:07] Already started tracking\n",
      "[codecarbon INFO @ 00:10:07] Energy consumed for RAM : 0.000259 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:10:08] Energy consumed for all CPUs : 0.000778 kWh. All CPUs Power : 7.268 W\n",
      "[codecarbon INFO @ 00:10:10] 0.001037 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:10:12] Already started tracking\n",
      "[codecarbon INFO @ 00:10:12] Energy consumed for RAM : 0.000261 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:10:13] Energy consumed for all CPUs : 0.000784 kWh. All CPUs Power : 11.021666666666668 W\n",
      "[codecarbon INFO @ 00:10:14] 0.001045 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:10:16] Already started tracking\n",
      "[codecarbon INFO @ 00:10:16] Energy consumed for RAM : 0.000262 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:10:18] Energy consumed for all CPUs : 0.000791 kWh. All CPUs Power : 11.120333333333333 W\n",
      "[codecarbon INFO @ 00:10:19] 0.001053 kWh of electricity used since the begining.\n",
      " 14%|█▍        | 11/78 [06:24<34:55, 31.28s/it][codecarbon WARNING @ 00:10:21] Already started tracking\n",
      "[codecarbon INFO @ 00:10:21] Energy consumed for RAM : 0.000264 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:10:23] Energy consumed for all CPUs : 0.000797 kWh. All CPUs Power : 11.131 W\n",
      "[codecarbon INFO @ 00:10:24] 0.001061 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:10:26] Already started tracking\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.293e-03, tolerance: 2.000e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.601e-03, tolerance: 2.000e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.427e-03, tolerance: 2.000e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.144e-03, tolerance: 2.000e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.015e-03, tolerance: 2.000e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.863e-03, tolerance: 2.000e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.294e-03, tolerance: 2.000e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.239e-03, tolerance: 2.000e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.145e-03, tolerance: 2.000e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.285e-03, tolerance: 2.000e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.248e-03, tolerance: 1.999e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.226e-03, tolerance: 1.999e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.161e-03, tolerance: 1.999e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.021e-03, tolerance: 1.999e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.144e-03, tolerance: 1.999e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.264e-03, tolerance: 1.999e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.104e-03, tolerance: 1.999e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.837e-03, tolerance: 1.999e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.193e-03, tolerance: 1.999e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.504e-03, tolerance: 1.999e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.451e-03, tolerance: 1.999e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.475e-03, tolerance: 1.999e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.214e-03, tolerance: 1.999e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[codecarbon INFO @ 00:10:37] Energy consumed for RAM : 0.000275 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:10:38] Energy consumed for all CPUs : 0.000837 kWh. All CPUs Power : 11.474499999999999 W\n",
      "[codecarbon INFO @ 00:10:40] 0.001112 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:10:42] Already started tracking\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.055e-02, tolerance: 1.995e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.032e-02, tolerance: 1.999e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[codecarbon WARNING @ 00:12:57] Background scheduler didn't run for a long period (137s), results might be inaccurate\n",
      "[codecarbon INFO @ 00:12:57] Energy consumed for RAM : 0.000389 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:12:59] Energy consumed for all CPUs : 0.001166 kWh. All CPUs Power : 8.607 W\n",
      "[codecarbon INFO @ 00:13:00] 0.001556 kWh of electricity used since the begining.\n",
      " 15%|█▌        | 12/78 [09:05<1:10:47, 64.36s/it][codecarbon WARNING @ 00:13:02] Already started tracking\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "[codecarbon INFO @ 00:13:02] Energy consumed for RAM : 0.000391 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:13:04] Energy consumed for all CPUs : 0.001174 kWh. All CPUs Power : 13.259500000000001 W\n",
      "[codecarbon INFO @ 00:13:05] 0.001565 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:13:07] Already started tracking\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "[codecarbon INFO @ 00:13:07] Energy consumed for RAM : 0.000393 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:13:09] Energy consumed for all CPUs : 0.001182 kWh. All CPUs Power : 13.4215 W\n",
      "[codecarbon INFO @ 00:13:10] 0.001575 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:13:12] Already started tracking\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "[codecarbon INFO @ 00:13:12] Energy consumed for RAM : 0.000395 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:13:13] Energy consumed for all CPUs : 0.001190 kWh. All CPUs Power : 13.579666666666668 W\n",
      "[codecarbon INFO @ 00:13:15] 0.001584 kWh of electricity used since the begining.\n",
      " 17%|█▋        | 13/78 [09:20<55:20, 51.08s/it]  [codecarbon WARNING @ 00:13:17] Already started tracking\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsCV())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "[codecarbon INFO @ 00:13:17] Energy consumed for RAM : 0.000396 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:13:18] Energy consumed for all CPUs : 0.001196 kWh. All CPUs Power : 10.800999999999997 W\n",
      "[codecarbon INFO @ 00:13:20] 0.001593 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:13:22] Already started tracking\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsCV())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "[codecarbon INFO @ 00:13:22] Energy consumed for RAM : 0.000398 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:13:23] Energy consumed for all CPUs : 0.001203 kWh. All CPUs Power : 9.709000000000003 W\n",
      "[codecarbon INFO @ 00:13:25] 0.001601 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:13:27] Already started tracking\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsCV())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "[codecarbon WARNING @ 00:14:03] Background scheduler didn't run for a long period (37s), results might be inaccurate\n",
      "[codecarbon INFO @ 00:14:03] Energy consumed for RAM : 0.000430 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:14:04] Energy consumed for all CPUs : 0.001340 kWh. All CPUs Power : 13.097 W\n",
      "[codecarbon INFO @ 00:14:05] 0.001770 kWh of electricity used since the begining.\n",
      " 18%|█▊        | 14/78 [10:10<54:21, 50.97s/it][codecarbon WARNING @ 00:14:08] Already started tracking\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "[codecarbon WARNING @ 00:14:08] Already started tracking\n",
      "[codecarbon INFO @ 00:14:08] Energy consumed for RAM : 0.000432 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:14:09] Energy consumed for all CPUs : 0.001347 kWh. All CPUs Power : 11.51975 W\n",
      "[codecarbon INFO @ 00:14:10] 0.001779 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:14:12] Already started tracking\n",
      "[codecarbon INFO @ 00:14:12] Energy consumed for RAM : 0.000433 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:14:14] Energy consumed for all CPUs : 0.001355 kWh. All CPUs Power : 13.058583333333333 W\n",
      "[codecarbon INFO @ 00:14:15] 0.001788 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:14:17] Already started tracking\n",
      "[codecarbon INFO @ 00:14:22] Energy consumed for RAM : 0.000439 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:14:24] Energy consumed for all CPUs : 0.001371 kWh. All CPUs Power : 7.972583333333334 W\n",
      "[codecarbon INFO @ 00:14:25] 0.001810 kWh of electricity used since the begining.\n",
      " 21%|██        | 16/78 [10:30<33:54, 32.82s/it][codecarbon WARNING @ 00:14:27] Already started tracking\n",
      "[codecarbon WARNING @ 00:14:27] Already started tracking\n",
      "[codecarbon INFO @ 00:14:27] Energy consumed for RAM : 0.000441 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:14:29] Energy consumed for all CPUs : 0.001377 kWh. All CPUs Power : 11.069583333333332 W\n",
      "[codecarbon INFO @ 00:14:30] 0.001818 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:14:32] Already started tracking\n",
      "[codecarbon INFO @ 00:14:32] Energy consumed for RAM : 0.000443 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:14:33] Energy consumed for all CPUs : 0.001384 kWh. All CPUs Power : 12.45191666666667 W\n",
      "[codecarbon INFO @ 00:14:35] 0.001827 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:14:37] Already started tracking\n",
      "[codecarbon INFO @ 00:14:37] Energy consumed for RAM : 0.000445 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:14:39] Energy consumed for all CPUs : 0.001390 kWh. All CPUs Power : 8.666500000000001 W\n",
      "[codecarbon INFO @ 00:14:40] 0.001835 kWh of electricity used since the begining.\n",
      " 23%|██▎       | 18/78 [10:45<23:01, 23.03s/it][codecarbon WARNING @ 00:14:42] Already started tracking\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "[codecarbon INFO @ 00:14:42] Energy consumed for RAM : 0.000447 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:14:44] Energy consumed for all CPUs : 0.001394 kWh. All CPUs Power : 5.887083333333333 W\n",
      "[codecarbon INFO @ 00:14:45] 0.001840 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:14:47] Already started tracking\n",
      "[codecarbon INFO @ 00:14:48] Energy consumed for RAM : 0.000449 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:14:49] Energy consumed for all CPUs : 0.001398 kWh. All CPUs Power : 6.657250000000001 W\n",
      "[codecarbon INFO @ 00:14:50] 0.001847 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:14:53] Already started tracking\n",
      "[codecarbon INFO @ 00:14:55] Energy consumed for RAM : 0.000452 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:14:56] Energy consumed for all CPUs : 0.001405 kWh. All CPUs Power : 6.2685 W\n",
      "[codecarbon INFO @ 00:14:57] 0.001857 kWh of electricity used since the begining.\n",
      " 24%|██▍       | 19/78 [11:02<21:23, 21.76s/it][codecarbon WARNING @ 00:14:59] Already started tracking\n",
      "[codecarbon WARNING @ 00:14:59] Already started tracking\n",
      "[codecarbon WARNING @ 00:14:59] Already started tracking\n",
      "[codecarbon WARNING @ 00:14:59] Already started tracking\n",
      "[codecarbon WARNING @ 00:14:59] Already started tracking\n",
      "[codecarbon WARNING @ 00:14:59] Already started tracking\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "[codecarbon INFO @ 00:14:59] Energy consumed for RAM : 0.000454 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:15:01] Energy consumed for all CPUs : 0.001410 kWh. All CPUs Power : 8.026333333333332 W\n",
      "[codecarbon INFO @ 00:15:02] 0.001864 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:15:04] Already started tracking\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "[codecarbon INFO @ 00:15:04] Energy consumed for RAM : 0.000456 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:15:06] Energy consumed for all CPUs : 0.001415 kWh. All CPUs Power : 8.851750000000001 W\n",
      "[codecarbon INFO @ 00:15:07] 0.001870 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:15:09] Already started tracking\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "[codecarbon INFO @ 00:15:09] Energy consumed for RAM : 0.000457 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:15:10] Energy consumed for all CPUs : 0.001422 kWh. All CPUs Power : 12.885166666666668 W\n",
      "[codecarbon INFO @ 00:15:12] 0.001880 kWh of electricity used since the begining.\n",
      " 32%|███▏      | 25/78 [11:17<08:07,  9.20s/it][codecarbon WARNING @ 00:15:14] Already started tracking\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuitCV())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "[codecarbon INFO @ 00:15:14] Energy consumed for RAM : 0.000459 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:15:15] Energy consumed for all CPUs : 0.001428 kWh. All CPUs Power : 10.196083333333332 W\n",
      "[codecarbon INFO @ 00:15:17] 0.001887 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:15:19] Already started tracking\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuitCV())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "[codecarbon INFO @ 00:15:19] Energy consumed for RAM : 0.000461 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:15:20] Energy consumed for all CPUs : 0.001435 kWh. All CPUs Power : 12.076916666666667 W\n",
      "[codecarbon INFO @ 00:15:22] 0.001896 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:15:24] Already started tracking\n",
      "/Users/emmaboehly/programmation/anaconda3/envs/lauzhack/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuitCV())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "[codecarbon INFO @ 00:15:24] Energy consumed for RAM : 0.000463 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:15:26] Energy consumed for all CPUs : 0.001442 kWh. All CPUs Power : 9.872416666666666 W\n",
      "[codecarbon INFO @ 00:15:27] 0.001905 kWh of electricity used since the begining.\n",
      " 33%|███▎      | 26/78 [11:32<08:39,  9.99s/it][codecarbon WARNING @ 00:15:29] Already started tracking\n",
      "[codecarbon INFO @ 00:15:29] Energy consumed for RAM : 0.000465 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:15:30] Energy consumed for all CPUs : 0.001448 kWh. All CPUs Power : 10.744750000000003 W\n",
      "[codecarbon INFO @ 00:15:32] 0.001913 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:15:34] Already started tracking\n",
      "[codecarbon INFO @ 00:15:34] Energy consumed for RAM : 0.000466 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:15:35] Energy consumed for all CPUs : 0.001454 kWh. All CPUs Power : 9.697666666666667 W\n",
      "[codecarbon INFO @ 00:15:37] 0.001920 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:15:39] Already started tracking\n",
      "[codecarbon INFO @ 00:15:39] Energy consumed for RAM : 0.000468 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:15:40] Energy consumed for all CPUs : 0.001462 kWh. All CPUs Power : 13.400916666666667 W\n",
      "[codecarbon INFO @ 00:15:42] 0.001930 kWh of electricity used since the begining.\n",
      " 35%|███▍      | 27/78 [11:46<09:07, 10.74s/it][codecarbon WARNING @ 00:15:44] Already started tracking\n",
      "[codecarbon INFO @ 00:15:44] Energy consumed for RAM : 0.000470 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:15:45] Energy consumed for all CPUs : 0.001468 kWh. All CPUs Power : 10.234666666666667 W\n",
      "[codecarbon INFO @ 00:15:46] 0.001937 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:15:48] Already started tracking\n",
      "[codecarbon INFO @ 00:15:48] Energy consumed for RAM : 0.000471 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:15:50] Energy consumed for all CPUs : 0.001475 kWh. All CPUs Power : 12.738166666666666 W\n",
      "[codecarbon INFO @ 00:15:51] 0.001946 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:15:53] Already started tracking\n",
      "[codecarbon INFO @ 00:15:54] Energy consumed for RAM : 0.000474 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:15:56] Energy consumed for all CPUs : 0.001486 kWh. All CPUs Power : 13.045416666666666 W\n",
      "[codecarbon INFO @ 00:15:57] 0.001960 kWh of electricity used since the begining.\n",
      " 36%|███▌      | 28/78 [12:02<09:41, 11.63s/it][codecarbon WARNING @ 00:15:59] Already started tracking\n",
      "[codecarbon INFO @ 00:15:59] Energy consumed for RAM : 0.000476 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:16:01] Energy consumed for all CPUs : 0.001494 kWh. All CPUs Power : 13.160083333333331 W\n",
      "[codecarbon INFO @ 00:16:02] 0.001970 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:16:04] Already started tracking\n",
      "[codecarbon INFO @ 00:16:04] Energy consumed for RAM : 0.000477 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:16:05] Energy consumed for all CPUs : 0.001501 kWh. All CPUs Power : 13.380333333333333 W\n",
      "[codecarbon INFO @ 00:16:07] 0.001979 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:16:09] Already started tracking\n",
      "[codecarbon INFO @ 00:16:09] Energy consumed for RAM : 0.000479 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:16:10] Energy consumed for all CPUs : 0.001508 kWh. All CPUs Power : 10.71475 W\n",
      "[codecarbon INFO @ 00:16:12] 0.001987 kWh of electricity used since the begining.\n",
      " 37%|███▋      | 29/78 [12:16<10:00, 12.25s/it][codecarbon WARNING @ 00:16:14] Already started tracking\n",
      "[codecarbon INFO @ 00:16:14] Energy consumed for RAM : 0.000481 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:16:15] Energy consumed for all CPUs : 0.001515 kWh. All CPUs Power : 12.40825 W\n",
      "[codecarbon INFO @ 00:16:17] 0.001996 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:16:19] Already started tracking\n",
      "[codecarbon INFO @ 00:16:19] Energy consumed for RAM : 0.000483 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:16:20] Energy consumed for all CPUs : 0.001520 kWh. All CPUs Power : 9.812500000000002 W\n",
      "[codecarbon INFO @ 00:16:21] 0.002003 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:16:23] Already started tracking\n",
      "[codecarbon INFO @ 00:16:23] Energy consumed for RAM : 0.000484 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:16:25] Energy consumed for all CPUs : 0.001526 kWh. All CPUs Power : 10.197916666666666 W\n",
      "[codecarbon INFO @ 00:16:26] 0.002010 kWh of electricity used since the begining.\n",
      " 38%|███▊      | 30/78 [12:31<10:13, 12.78s/it][codecarbon WARNING @ 00:16:28] Already started tracking\n",
      "[codecarbon INFO @ 00:16:28] Energy consumed for RAM : 0.000486 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:16:30] Energy consumed for all CPUs : 0.001532 kWh. All CPUs Power : 10.845333333333336 W\n",
      "[codecarbon INFO @ 00:16:31] 0.002018 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:16:33] Already started tracking\n",
      "[codecarbon INFO @ 00:16:33] Energy consumed for RAM : 0.000488 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:16:35] Energy consumed for all CPUs : 0.001540 kWh. All CPUs Power : 12.887833333333333 W\n",
      "[codecarbon INFO @ 00:16:36] 0.002028 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:16:38] Already started tracking\n",
      "[codecarbon INFO @ 00:16:52] Energy consumed for RAM : 0.000501 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:16:54] Energy consumed for all CPUs : 0.001580 kWh. All CPUs Power : 8.799750000000001 W\n",
      "[codecarbon INFO @ 00:16:55] 0.002081 kWh of electricity used since the begining.\n",
      " 40%|███▉      | 31/78 [13:00<13:09, 16.80s/it][codecarbon WARNING @ 00:16:57] Already started tracking\n",
      "[codecarbon WARNING @ 00:16:57] Already started tracking\n",
      "[codecarbon INFO @ 00:16:57] Energy consumed for RAM : 0.000503 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:16:59] Energy consumed for all CPUs : 0.001587 kWh. All CPUs Power : 11.817333333333332 W\n",
      "[codecarbon INFO @ 00:17:01] 0.002090 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:17:03] Already started tracking\n",
      "[codecarbon INFO @ 00:17:03] Energy consumed for RAM : 0.000505 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:17:04] Energy consumed for all CPUs : 0.001595 kWh. All CPUs Power : 13.140833333333335 W\n",
      "[codecarbon INFO @ 00:17:06] 0.002100 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:17:08] Already started tracking\n",
      "[codecarbon INFO @ 00:17:08] Energy consumed for RAM : 0.000507 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:17:10] Energy consumed for all CPUs : 0.001604 kWh. All CPUs Power : 13.082666666666668 W\n",
      "[codecarbon INFO @ 00:17:11] 0.002112 kWh of electricity used since the begining.\n",
      " 42%|████▏     | 33/78 [13:16<09:49, 13.10s/it][codecarbon WARNING @ 00:17:13] Already started tracking\n",
      "[codecarbon INFO @ 00:17:13] Energy consumed for RAM : 0.000509 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:17:14] Energy consumed for all CPUs : 0.001608 kWh. All CPUs Power : 7.095833333333334 W\n",
      "[codecarbon INFO @ 00:17:16] 0.002117 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:17:18] Already started tracking\n",
      "[codecarbon INFO @ 00:17:18] Energy consumed for RAM : 0.000511 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:17:19] Energy consumed for all CPUs : 0.001612 kWh. All CPUs Power : 6.4736666666666665 W\n",
      "[codecarbon INFO @ 00:17:21] 0.002123 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:17:23] Already started tracking\n",
      "[codecarbon INFO @ 00:17:23] Energy consumed for RAM : 0.000513 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:17:25] Energy consumed for all CPUs : 0.001617 kWh. All CPUs Power : 6.479166666666668 W\n",
      "[codecarbon INFO @ 00:17:26] 0.002129 kWh of electricity used since the begining.\n",
      " 44%|████▎     | 34/78 [13:31<09:55, 13.53s/it][codecarbon WARNING @ 00:17:28] Already started tracking\n",
      "[codecarbon INFO @ 00:17:28] Energy consumed for RAM : 0.000514 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:17:29] Energy consumed for all CPUs : 0.001620 kWh. All CPUs Power : 5.939750000000001 W\n",
      "[codecarbon INFO @ 00:17:31] 0.002134 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:17:33] Already started tracking\n",
      "[codecarbon INFO @ 00:17:33] Energy consumed for RAM : 0.000516 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:17:34] Energy consumed for all CPUs : 0.001626 kWh. All CPUs Power : 9.784916666666668 W\n",
      "[codecarbon INFO @ 00:17:36] 0.002142 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:17:38] Already started tracking\n",
      "[codecarbon INFO @ 00:17:38] Energy consumed for RAM : 0.000518 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:17:39] Energy consumed for all CPUs : 0.001632 kWh. All CPUs Power : 10.797416666666665 W\n",
      "[codecarbon INFO @ 00:17:41] 0.002150 kWh of electricity used since the begining.\n",
      " 45%|████▍     | 35/78 [13:46<09:56, 13.86s/it][codecarbon WARNING @ 00:17:43] Already started tracking\n",
      "[codecarbon INFO @ 00:17:43] Energy consumed for RAM : 0.000520 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:17:44] Energy consumed for all CPUs : 0.001636 kWh. All CPUs Power : 6.505583333333333 W\n",
      "[codecarbon INFO @ 00:17:46] 0.002156 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:17:48] Already started tracking\n",
      "[codecarbon INFO @ 00:17:48] Energy consumed for RAM : 0.000521 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:17:49] Energy consumed for all CPUs : 0.001643 kWh. All CPUs Power : 12.731416666666668 W\n",
      "[codecarbon INFO @ 00:17:51] 0.002165 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:17:53] Already started tracking\n",
      "[codecarbon INFO @ 00:17:53] Energy consumed for RAM : 0.000524 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:17:55] Energy consumed for all CPUs : 0.001652 kWh. All CPUs Power : 12.144583333333332 W\n",
      "[codecarbon INFO @ 00:17:56] 0.002176 kWh of electricity used since the begining.\n",
      " 46%|████▌     | 36/78 [14:01<09:59, 14.27s/it][codecarbon WARNING @ 00:17:58] Already started tracking\n",
      "[codecarbon INFO @ 00:17:58] Energy consumed for RAM : 0.000525 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:18:00] Energy consumed for all CPUs : 0.001657 kWh. All CPUs Power : 8.86525 W\n",
      "[codecarbon INFO @ 00:18:01] 0.002182 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:18:03] Already started tracking\n",
      "[codecarbon INFO @ 00:18:03] Energy consumed for RAM : 0.000527 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:18:05] Energy consumed for all CPUs : 0.001664 kWh. All CPUs Power : 12.327333333333335 W\n",
      "[codecarbon INFO @ 00:18:06] 0.002191 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:18:08] Already started tracking\n",
      "[codecarbon INFO @ 00:18:08] Energy consumed for RAM : 0.000529 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:18:10] Energy consumed for all CPUs : 0.001671 kWh. All CPUs Power : 10.725999999999999 W\n",
      "[codecarbon INFO @ 00:18:11] 0.002200 kWh of electricity used since the begining.\n",
      " 47%|████▋     | 37/78 [14:16<09:54, 14.49s/it][codecarbon WARNING @ 00:18:13] Already started tracking\n",
      "[codecarbon INFO @ 00:18:13] Energy consumed for RAM : 0.000531 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:18:15] Energy consumed for all CPUs : 0.001679 kWh. All CPUs Power : 12.516166666666669 W\n",
      "[codecarbon INFO @ 00:18:16] 0.002210 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:18:19] Already started tracking\n",
      "[codecarbon INFO @ 00:18:19] Energy consumed for RAM : 0.000532 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:18:20] Energy consumed for all CPUs : 0.001686 kWh. All CPUs Power : 13.510583333333335 W\n",
      "[codecarbon INFO @ 00:18:21] 0.002219 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:18:23] Already started tracking\n",
      "[codecarbon INFO @ 00:18:24] Energy consumed for RAM : 0.000534 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:18:25] Energy consumed for all CPUs : 0.001693 kWh. All CPUs Power : 10.00475 W\n",
      "[codecarbon INFO @ 00:18:27] 0.002227 kWh of electricity used since the begining.\n",
      " 49%|████▊     | 38/78 [14:32<09:59, 14.99s/it][codecarbon WARNING @ 00:18:30] Already started tracking\n",
      "[codecarbon INFO @ 00:18:30] Energy consumed for RAM : 0.000537 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:18:31] Energy consumed for all CPUs : 0.001704 kWh. All CPUs Power : 13.311833333333334 W\n",
      "[codecarbon INFO @ 00:18:33] 0.002241 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:18:35] Already started tracking\n",
      "[codecarbon INFO @ 00:18:35] Energy consumed for RAM : 0.000539 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:18:36] Energy consumed for all CPUs : 0.001711 kWh. All CPUs Power : 12.859333333333334 W\n",
      "[codecarbon INFO @ 00:18:38] 0.002250 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:18:40] Already started tracking\n",
      "[codecarbon INFO @ 00:18:40] Energy consumed for RAM : 0.000541 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:18:42] Energy consumed for all CPUs : 0.001719 kWh. All CPUs Power : 10.892333333333333 W\n",
      "[codecarbon INFO @ 00:18:43] 0.002260 kWh of electricity used since the begining.\n",
      " 50%|█████     | 39/78 [14:48<09:50, 15.13s/it][codecarbon WARNING @ 00:18:45] Already started tracking\n",
      "[codecarbon WARNING @ 00:18:45] Already started tracking\n",
      "[codecarbon INFO @ 00:18:45] Energy consumed for RAM : 0.000542 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:18:47] Energy consumed for all CPUs : 0.001726 kWh. All CPUs Power : 10.879 W\n",
      "[codecarbon INFO @ 00:18:48] 0.002268 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:18:50] Already started tracking\n",
      "[codecarbon INFO @ 00:18:51] Energy consumed for RAM : 0.000545 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:18:52] Energy consumed for all CPUs : 0.001734 kWh. All CPUs Power : 10.743916666666665 W\n",
      "[codecarbon INFO @ 00:18:54] 0.002278 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:18:56] Already started tracking\n",
      "[codecarbon INFO @ 00:19:06] Energy consumed for RAM : 0.000555 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:19:07] Energy consumed for all CPUs : 0.001764 kWh. All CPUs Power : 9.312166666666668 W\n",
      "[codecarbon INFO @ 00:19:09] 0.002319 kWh of electricity used since the begining.\n",
      " 53%|█████▎    | 41/78 [15:14<08:43, 14.14s/it][codecarbon WARNING @ 00:19:11] Already started tracking\n",
      "[codecarbon INFO @ 00:19:11] Energy consumed for RAM : 0.000556 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:19:12] Energy consumed for all CPUs : 0.001771 kWh. All CPUs Power : 11.2515 W\n",
      "[codecarbon INFO @ 00:19:14] 0.002327 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:19:16] Already started tracking\n",
      "[codecarbon INFO @ 00:19:16] Energy consumed for RAM : 0.000558 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:19:17] Energy consumed for all CPUs : 0.001778 kWh. All CPUs Power : 12.548583333333333 W\n",
      "[codecarbon INFO @ 00:19:19] 0.002336 kWh of electricity used since the begining.\n",
      "[codecarbon WARNING @ 00:19:21] Already started tracking\n",
      "[codecarbon INFO @ 00:19:21] Energy consumed for RAM : 0.000560 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 00:19:23] Energy consumed for all CPUs : 0.001786 kWh. All CPUs Power : 11.117666666666667 W\n",
      "[codecarbon INFO @ 00:19:24] 0.002346 kWh of electricity used since the begining.\n",
      " 54%|█████▍    | 42/78 [15:29<08:40, 14.46s/it][codecarbon WARNING @ 00:19:26] Already started tracking\n",
      "[codecarbon WARNING @ 00:19:26] Already started tracking\n",
      "[codecarbon WARNING @ 00:19:26] Already started tracking\n",
      "[codecarbon WARNING @ 00:19:26] Already started tracking\n",
      "[codecarbon WARNING @ 00:19:26] Already started tracking\n",
      "[codecarbon WARNING @ 00:19:26] Already started tracking\n",
      "[codecarbon WARNING @ 00:19:26] Already started tracking\n",
      "100%|██████████| 78/78 [15:29<00:00, 11.92s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'finished !'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_generator(nb_dataset_=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 19:07:36] Energy consumed for RAM : 0.000008 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 19:07:54] Energy consumed for RAM : 0.000032 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 19:07:55] Energy consumed for RAM : 0.000057 kWh. RAM Power : 3.0 W\n",
      "[codecarbon INFO @ 19:07:55] Energy consumed for all CPUs : 0.000031 kWh. All CPUs Power : 11.10425 W\n",
      "[codecarbon INFO @ 19:07:56] Energy consumed for all CPUs : 0.000105 kWh. All CPUs Power : 9.132583333333333 W\n",
      "[codecarbon INFO @ 19:07:56] Energy consumed for all CPUs : 0.000181 kWh. All CPUs Power : 9.434416666666666 W\n",
      "ERROR: EnergyDriver_executeCommands [via readSample] returned 0xe00002bc\n",
      "[codecarbon INFO @ 19:07:56] 0.000237 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 19:07:57] 0.000237 kWh of electricity used since the begining.\n",
      "ERROR: EnergyDriver_executeCommands [via readSample] returned 0xe00002bc\n",
      "[codecarbon INFO @ 19:07:57] 0.000237 kWh of electricity used since the begining.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.80304964589005e-06"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracker.start()\n",
    "reg = LinearRegression().fit(X, y)\n",
    "tracker.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System Time</th>\n",
       "      <th>RDTSC</th>\n",
       "      <th>Elapsed Time (sec)</th>\n",
       "      <th>CPU Utilization(%)</th>\n",
       "      <th>CPU Frequency_0(MHz)</th>\n",
       "      <th>CPU Min Frequency_0(MHz)</th>\n",
       "      <th>CPU Max Frequency_0(MHz)</th>\n",
       "      <th>CPU Requsted Frequency_0(MHz)</th>\n",
       "      <th>Processor Power_0(Watt)</th>\n",
       "      <th>Cumulative Processor Energy_0(Joules)</th>\n",
       "      <th>...</th>\n",
       "      <th>Package Temperature_0(C)</th>\n",
       "      <th>Package Hot_0</th>\n",
       "      <th>CPU Min Temperature_0(C)</th>\n",
       "      <th>CPU Max Temperature_0(C)</th>\n",
       "      <th>DRAM Power_0(Watt)</th>\n",
       "      <th>Cumulative DRAM Energy_0(Joules)</th>\n",
       "      <th>Cumulative DRAM Energy_0(mWh)</th>\n",
       "      <th>Package Power Limit_0(Watt)</th>\n",
       "      <th>GT Frequency(MHz)</th>\n",
       "      <th>GT Requsted Frequency(MHz)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19:07:56:704</td>\n",
       "      <td>1.259358e+13</td>\n",
       "      <td>0.102</td>\n",
       "      <td>28.102</td>\n",
       "      <td>2648.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>2895.0</td>\n",
       "      <td>13.190</td>\n",
       "      <td>1.346</td>\n",
       "      <td>...</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.026</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19:07:56:812</td>\n",
       "      <td>1.259390e+13</td>\n",
       "      <td>0.210</td>\n",
       "      <td>24.254</td>\n",
       "      <td>2963.0</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>3036.0</td>\n",
       "      <td>11.979</td>\n",
       "      <td>2.634</td>\n",
       "      <td>...</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.051</td>\n",
       "      <td>28.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19:07:56:913</td>\n",
       "      <td>1.259419e+13</td>\n",
       "      <td>0.310</td>\n",
       "      <td>19.372</td>\n",
       "      <td>1933.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>8.584</td>\n",
       "      <td>3.499</td>\n",
       "      <td>...</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.072</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19:07:57:015</td>\n",
       "      <td>1.259449e+13</td>\n",
       "      <td>0.413</td>\n",
       "      <td>19.477</td>\n",
       "      <td>1755.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>1762.0</td>\n",
       "      <td>7.981</td>\n",
       "      <td>4.320</td>\n",
       "      <td>...</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.095</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19:07:57:118</td>\n",
       "      <td>1.259479e+13</td>\n",
       "      <td>0.516</td>\n",
       "      <td>21.798</td>\n",
       "      <td>1887.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>1938.0</td>\n",
       "      <td>8.363</td>\n",
       "      <td>5.182</td>\n",
       "      <td>...</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.116</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19:07:57:220</td>\n",
       "      <td>1.259508e+13</td>\n",
       "      <td>0.618</td>\n",
       "      <td>16.324</td>\n",
       "      <td>1791.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>2600.0</td>\n",
       "      <td>1798.0</td>\n",
       "      <td>5.729</td>\n",
       "      <td>5.766</td>\n",
       "      <td>...</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.137</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19:07:57:321</td>\n",
       "      <td>1.259537e+13</td>\n",
       "      <td>0.719</td>\n",
       "      <td>21.645</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>2600.0</td>\n",
       "      <td>1653.0</td>\n",
       "      <td>6.357</td>\n",
       "      <td>6.406</td>\n",
       "      <td>...</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.563</td>\n",
       "      <td>0.156</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>19:07:57:423</td>\n",
       "      <td>1.259567e+13</td>\n",
       "      <td>0.821</td>\n",
       "      <td>15.607</td>\n",
       "      <td>1615.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>1678.0</td>\n",
       "      <td>6.677</td>\n",
       "      <td>7.088</td>\n",
       "      <td>...</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.177</td>\n",
       "      <td>28.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19:07:57:524</td>\n",
       "      <td>1.259596e+13</td>\n",
       "      <td>0.922</td>\n",
       "      <td>15.248</td>\n",
       "      <td>1603.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>1599.0</td>\n",
       "      <td>5.597</td>\n",
       "      <td>7.654</td>\n",
       "      <td>...</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.196</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19:07:57:625</td>\n",
       "      <td>1.259626e+13</td>\n",
       "      <td>1.023</td>\n",
       "      <td>17.340</td>\n",
       "      <td>2393.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>2430.0</td>\n",
       "      <td>6.902</td>\n",
       "      <td>8.351</td>\n",
       "      <td>...</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.216</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>19:07:57:726</td>\n",
       "      <td>1.259655e+13</td>\n",
       "      <td>1.124</td>\n",
       "      <td>18.434</td>\n",
       "      <td>2439.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>2457.0</td>\n",
       "      <td>9.511</td>\n",
       "      <td>9.306</td>\n",
       "      <td>...</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.237</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Total Elapsed Time (sec) = 1.123542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Measured RDTSC Frequency (GHz) = 2.904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Cumulative Package Energy_0 (Joules) = 9.306030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Cumulative Package Energy_0 (mWh) = 2.585008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Average Package Power_0 (Watt) = 8.282759</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Cumulative IA Energy_0 (Joules) = 5.138733</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Cumulative IA Energy_0 (mWh) = 1.427426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Average Package IA_0 (Watt) = 4.573689</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Cumulative DRAM Energy_0 (Joules) = 0.852600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Cumulative DRAM Energy_0 (mWh) = 0.236833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Average Package DRAM_0 (Watt) = 0.758850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>es) = 5.872009\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Cumulative IA Energy_0 (mWh) = 1.631114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Average Package IA_0 (Watt) = 4.780797</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Cumulative DRAM Energy_0 (Joules) = 0.951843</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Cumulative DRAM Energy_0 (mWh) = 0.264401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Average Package DRAM_0 (Watt) = 0.774959</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        System Time         RDTSC  \\\n",
       "0                                      19:07:56:704  1.259358e+13   \n",
       "1                                      19:07:56:812  1.259390e+13   \n",
       "2                                      19:07:56:913  1.259419e+13   \n",
       "3                                      19:07:57:015  1.259449e+13   \n",
       "4                                      19:07:57:118  1.259479e+13   \n",
       "5                                      19:07:57:220  1.259508e+13   \n",
       "6                                      19:07:57:321  1.259537e+13   \n",
       "7                                      19:07:57:423  1.259567e+13   \n",
       "8                                      19:07:57:524  1.259596e+13   \n",
       "9                                      19:07:57:625  1.259626e+13   \n",
       "10                                     19:07:57:726  1.259655e+13   \n",
       "11              Total Elapsed Time (sec) = 1.123542           NaN   \n",
       "12           Measured RDTSC Frequency (GHz) = 2.904           NaN   \n",
       "13  Cumulative Package Energy_0 (Joules) = 9.306030           NaN   \n",
       "14     Cumulative Package Energy_0 (mWh) = 2.585008           NaN   \n",
       "15        Average Package Power_0 (Watt) = 8.282759           NaN   \n",
       "16       Cumulative IA Energy_0 (Joules) = 5.138733           NaN   \n",
       "17          Cumulative IA Energy_0 (mWh) = 1.427426           NaN   \n",
       "18           Average Package IA_0 (Watt) = 4.573689           NaN   \n",
       "19     Cumulative DRAM Energy_0 (Joules) = 0.852600           NaN   \n",
       "20        Cumulative DRAM Energy_0 (mWh) = 0.236833           NaN   \n",
       "21         Average Package DRAM_0 (Watt) = 0.758850           NaN   \n",
       "22                                  es) = 5.872009\"           NaN   \n",
       "23          Cumulative IA Energy_0 (mWh) = 1.631114           NaN   \n",
       "24           Average Package IA_0 (Watt) = 4.780797           NaN   \n",
       "25     Cumulative DRAM Energy_0 (Joules) = 0.951843           NaN   \n",
       "26        Cumulative DRAM Energy_0 (mWh) = 0.264401           NaN   \n",
       "27         Average Package DRAM_0 (Watt) = 0.774959           NaN   \n",
       "\n",
       "    Elapsed Time (sec)  CPU Utilization(%)  CPU Frequency_0(MHz)  \\\n",
       "0                0.102              28.102                2648.0   \n",
       "1                0.210              24.254                2963.0   \n",
       "2                0.310              19.372                1933.0   \n",
       "3                0.413              19.477                1755.0   \n",
       "4                0.516              21.798                1887.0   \n",
       "5                0.618              16.324                1791.0   \n",
       "6                0.719              21.645                1643.0   \n",
       "7                0.821              15.607                1615.0   \n",
       "8                0.922              15.248                1603.0   \n",
       "9                1.023              17.340                2393.0   \n",
       "10               1.124              18.434                2439.0   \n",
       "11                 NaN                 NaN                   NaN   \n",
       "12                 NaN                 NaN                   NaN   \n",
       "13                 NaN                 NaN                   NaN   \n",
       "14                 NaN                 NaN                   NaN   \n",
       "15                 NaN                 NaN                   NaN   \n",
       "16                 NaN                 NaN                   NaN   \n",
       "17                 NaN                 NaN                   NaN   \n",
       "18                 NaN                 NaN                   NaN   \n",
       "19                 NaN                 NaN                   NaN   \n",
       "20                 NaN                 NaN                   NaN   \n",
       "21                 NaN                 NaN                   NaN   \n",
       "22                 NaN                 NaN                   NaN   \n",
       "23                 NaN                 NaN                   NaN   \n",
       "24                 NaN                 NaN                   NaN   \n",
       "25                 NaN                 NaN                   NaN   \n",
       "26                 NaN                 NaN                   NaN   \n",
       "27                 NaN                 NaN                   NaN   \n",
       "\n",
       "    CPU Min Frequency_0(MHz)  CPU Max Frequency_0(MHz)  \\\n",
       "0                     1200.0                    3100.0   \n",
       "1                     1300.0                    3100.0   \n",
       "2                     1200.0                    3100.0   \n",
       "3                     1200.0                    3100.0   \n",
       "4                     1200.0                    3100.0   \n",
       "5                     1200.0                    2600.0   \n",
       "6                     1200.0                    2600.0   \n",
       "7                     1200.0                    2800.0   \n",
       "8                     1200.0                    3100.0   \n",
       "9                     1200.0                    3100.0   \n",
       "10                    1200.0                    3300.0   \n",
       "11                       NaN                       NaN   \n",
       "12                       NaN                       NaN   \n",
       "13                       NaN                       NaN   \n",
       "14                       NaN                       NaN   \n",
       "15                       NaN                       NaN   \n",
       "16                       NaN                       NaN   \n",
       "17                       NaN                       NaN   \n",
       "18                       NaN                       NaN   \n",
       "19                       NaN                       NaN   \n",
       "20                       NaN                       NaN   \n",
       "21                       NaN                       NaN   \n",
       "22                       NaN                       NaN   \n",
       "23                       NaN                       NaN   \n",
       "24                       NaN                       NaN   \n",
       "25                       NaN                       NaN   \n",
       "26                       NaN                       NaN   \n",
       "27                       NaN                       NaN   \n",
       "\n",
       "    CPU Requsted Frequency_0(MHz)  Processor Power_0(Watt)  \\\n",
       "0                          2895.0                   13.190   \n",
       "1                          3036.0                   11.979   \n",
       "2                          1981.0                    8.584   \n",
       "3                          1762.0                    7.981   \n",
       "4                          1938.0                    8.363   \n",
       "5                          1798.0                    5.729   \n",
       "6                          1653.0                    6.357   \n",
       "7                          1678.0                    6.677   \n",
       "8                          1599.0                    5.597   \n",
       "9                          2430.0                    6.902   \n",
       "10                         2457.0                    9.511   \n",
       "11                            NaN                      NaN   \n",
       "12                            NaN                      NaN   \n",
       "13                            NaN                      NaN   \n",
       "14                            NaN                      NaN   \n",
       "15                            NaN                      NaN   \n",
       "16                            NaN                      NaN   \n",
       "17                            NaN                      NaN   \n",
       "18                            NaN                      NaN   \n",
       "19                            NaN                      NaN   \n",
       "20                            NaN                      NaN   \n",
       "21                            NaN                      NaN   \n",
       "22                            NaN                      NaN   \n",
       "23                            NaN                      NaN   \n",
       "24                            NaN                      NaN   \n",
       "25                            NaN                      NaN   \n",
       "26                            NaN                      NaN   \n",
       "27                            NaN                      NaN   \n",
       "\n",
       "    Cumulative Processor Energy_0(Joules)  ...  Package Temperature_0(C)  \\\n",
       "0                                   1.346  ...                      77.0   \n",
       "1                                   2.634  ...                      81.0   \n",
       "2                                   3.499  ...                      75.0   \n",
       "3                                   4.320  ...                      74.0   \n",
       "4                                   5.182  ...                      74.0   \n",
       "5                                   5.766  ...                      73.0   \n",
       "6                                   6.406  ...                      73.0   \n",
       "7                                   7.088  ...                      73.0   \n",
       "8                                   7.654  ...                      73.0   \n",
       "9                                   8.351  ...                      73.0   \n",
       "10                                  9.306  ...                      74.0   \n",
       "11                                    NaN  ...                       NaN   \n",
       "12                                    NaN  ...                       NaN   \n",
       "13                                    NaN  ...                       NaN   \n",
       "14                                    NaN  ...                       NaN   \n",
       "15                                    NaN  ...                       NaN   \n",
       "16                                    NaN  ...                       NaN   \n",
       "17                                    NaN  ...                       NaN   \n",
       "18                                    NaN  ...                       NaN   \n",
       "19                                    NaN  ...                       NaN   \n",
       "20                                    NaN  ...                       NaN   \n",
       "21                                    NaN  ...                       NaN   \n",
       "22                                    NaN  ...                       NaN   \n",
       "23                                    NaN  ...                       NaN   \n",
       "24                                    NaN  ...                       NaN   \n",
       "25                                    NaN  ...                       NaN   \n",
       "26                                    NaN  ...                       NaN   \n",
       "27                                    NaN  ...                       NaN   \n",
       "\n",
       "    Package Hot_0  CPU Min Temperature_0(C)  CPU Max Temperature_0(C)  \\\n",
       "0             0.0                      74.0                      82.0   \n",
       "1             0.0                      74.0                      82.0   \n",
       "2             0.0                      73.0                      79.0   \n",
       "3             0.0                      71.0                      76.0   \n",
       "4             0.0                      71.0                      78.0   \n",
       "5             0.0                      70.0                      74.0   \n",
       "6             0.0                      70.0                      74.0   \n",
       "7             0.0                      70.0                      77.0   \n",
       "8             0.0                      70.0                      74.0   \n",
       "9             0.0                      70.0                      74.0   \n",
       "10            0.0                      71.0                      78.0   \n",
       "11            NaN                       NaN                       NaN   \n",
       "12            NaN                       NaN                       NaN   \n",
       "13            NaN                       NaN                       NaN   \n",
       "14            NaN                       NaN                       NaN   \n",
       "15            NaN                       NaN                       NaN   \n",
       "16            NaN                       NaN                       NaN   \n",
       "17            NaN                       NaN                       NaN   \n",
       "18            NaN                       NaN                       NaN   \n",
       "19            NaN                       NaN                       NaN   \n",
       "20            NaN                       NaN                       NaN   \n",
       "21            NaN                       NaN                       NaN   \n",
       "22            NaN                       NaN                       NaN   \n",
       "23            NaN                       NaN                       NaN   \n",
       "24            NaN                       NaN                       NaN   \n",
       "25            NaN                       NaN                       NaN   \n",
       "26            NaN                       NaN                       NaN   \n",
       "27            NaN                       NaN                       NaN   \n",
       "\n",
       "    DRAM Power_0(Watt)  Cumulative DRAM Energy_0(Joules)  \\\n",
       "0                0.923                             0.094   \n",
       "1                0.826                             0.183   \n",
       "2                0.748                             0.258   \n",
       "3                0.805                             0.341   \n",
       "4                0.737                             0.417   \n",
       "5                0.729                             0.492   \n",
       "6                0.708                             0.563   \n",
       "7                0.715                             0.636   \n",
       "8                0.695                             0.706   \n",
       "9                0.707                             0.778   \n",
       "10               0.748                             0.853   \n",
       "11                 NaN                               NaN   \n",
       "12                 NaN                               NaN   \n",
       "13                 NaN                               NaN   \n",
       "14                 NaN                               NaN   \n",
       "15                 NaN                               NaN   \n",
       "16                 NaN                               NaN   \n",
       "17                 NaN                               NaN   \n",
       "18                 NaN                               NaN   \n",
       "19                 NaN                               NaN   \n",
       "20                 NaN                               NaN   \n",
       "21                 NaN                               NaN   \n",
       "22                 NaN                               NaN   \n",
       "23                 NaN                               NaN   \n",
       "24                 NaN                               NaN   \n",
       "25                 NaN                               NaN   \n",
       "26                 NaN                               NaN   \n",
       "27                 NaN                               NaN   \n",
       "\n",
       "    Cumulative DRAM Energy_0(mWh)  Package Power Limit_0(Watt)  \\\n",
       "0                           0.026                         28.0   \n",
       "1                           0.051                         28.0   \n",
       "2                           0.072                         28.0   \n",
       "3                           0.095                         28.0   \n",
       "4                           0.116                         28.0   \n",
       "5                           0.137                         28.0   \n",
       "6                           0.156                         28.0   \n",
       "7                           0.177                         28.0   \n",
       "8                           0.196                         28.0   \n",
       "9                           0.216                         28.0   \n",
       "10                          0.237                         28.0   \n",
       "11                            NaN                          NaN   \n",
       "12                            NaN                          NaN   \n",
       "13                            NaN                          NaN   \n",
       "14                            NaN                          NaN   \n",
       "15                            NaN                          NaN   \n",
       "16                            NaN                          NaN   \n",
       "17                            NaN                          NaN   \n",
       "18                            NaN                          NaN   \n",
       "19                            NaN                          NaN   \n",
       "20                            NaN                          NaN   \n",
       "21                            NaN                          NaN   \n",
       "22                            NaN                          NaN   \n",
       "23                            NaN                          NaN   \n",
       "24                            NaN                          NaN   \n",
       "25                            NaN                          NaN   \n",
       "26                            NaN                          NaN   \n",
       "27                            NaN                          NaN   \n",
       "\n",
       "    GT Frequency(MHz)  GT Requsted Frequency(MHz)  \n",
       "0                 0.0                         0.0  \n",
       "1               500.0                       500.0  \n",
       "2                 0.0                         0.0  \n",
       "3                 0.0                         0.0  \n",
       "4                 0.0                         0.0  \n",
       "5                 0.0                         0.0  \n",
       "6                 0.0                         0.0  \n",
       "7               500.0                       500.0  \n",
       "8                 0.0                         0.0  \n",
       "9                 0.0                         0.0  \n",
       "10                0.0                         0.0  \n",
       "11                NaN                         NaN  \n",
       "12                NaN                         NaN  \n",
       "13                NaN                         NaN  \n",
       "14                NaN                         NaN  \n",
       "15                NaN                         NaN  \n",
       "16                NaN                         NaN  \n",
       "17                NaN                         NaN  \n",
       "18                NaN                         NaN  \n",
       "19                NaN                         NaN  \n",
       "20                NaN                         NaN  \n",
       "21                NaN                         NaN  \n",
       "22                NaN                         NaN  \n",
       "23                NaN                         NaN  \n",
       "24                NaN                         NaN  \n",
       "25                NaN                         NaN  \n",
       "26                NaN                         NaN  \n",
       "27                NaN                         NaN  \n",
       "\n",
       "[28 rows x 24 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"intel_power_gadget_log.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'python_version': '3.9.15.final.0 (64 bit)',\n",
       " 'cpuinfo_version': [9, 0, 0],\n",
       " 'cpuinfo_version_string': '9.0.0',\n",
       " 'arch': 'X86_64',\n",
       " 'bits': 64,\n",
       " 'count': 4,\n",
       " 'arch_string_raw': 'x86_64',\n",
       " 'vendor_id_raw': 'GenuineIntel',\n",
       " 'brand_raw': 'Intel(R) Core(TM) i5-6267U CPU @ 2.90GHz',\n",
       " 'hz_advertised_friendly': '2.9000 GHz',\n",
       " 'hz_actual_friendly': '2.9000 GHz',\n",
       " 'hz_advertised': [2900000000, 0],\n",
       " 'hz_actual': [2900000000, 0],\n",
       " 'l2_cache_size': 262144,\n",
       " 'stepping': 3,\n",
       " 'model': 78,\n",
       " 'family': 6,\n",
       " 'flags': ['1gbpage',\n",
       "  '3dnowprefetch',\n",
       "  'abm',\n",
       "  'acapmsr',\n",
       "  'acpi',\n",
       "  'adx',\n",
       "  'aes',\n",
       "  'apic',\n",
       "  'avx',\n",
       "  'avx1.0',\n",
       "  'avx2',\n",
       "  'bmi1',\n",
       "  'bmi2',\n",
       "  'clflush',\n",
       "  'clflushopt',\n",
       "  'clfsh',\n",
       "  'clfsopt',\n",
       "  'cmov',\n",
       "  'cx16',\n",
       "  'cx8',\n",
       "  'de',\n",
       "  'ds',\n",
       "  'ds_cpl',\n",
       "  'dscpl',\n",
       "  'dtes64',\n",
       "  'dts',\n",
       "  'em64t',\n",
       "  'erms',\n",
       "  'est',\n",
       "  'f16c',\n",
       "  'fma',\n",
       "  'fpu',\n",
       "  'fpu_csds',\n",
       "  'fxsr',\n",
       "  'ht',\n",
       "  'htt',\n",
       "  'ibrs',\n",
       "  'intel_pt',\n",
       "  'invpcid',\n",
       "  'ipt',\n",
       "  'l1df',\n",
       "  'lahf',\n",
       "  'lahf_lm',\n",
       "  'lzcnt',\n",
       "  'mca',\n",
       "  'mce',\n",
       "  'mdclear',\n",
       "  'mmx',\n",
       "  'mon',\n",
       "  'monitor',\n",
       "  'movbe',\n",
       "  'mpx',\n",
       "  'msr',\n",
       "  'mtrr',\n",
       "  'osxsave',\n",
       "  'pae',\n",
       "  'pat',\n",
       "  'pbe',\n",
       "  'pcid',\n",
       "  'pclmulqdq',\n",
       "  'pdcm',\n",
       "  'pge',\n",
       "  'pni',\n",
       "  'popcnt',\n",
       "  'prefetchw',\n",
       "  'pse',\n",
       "  'pse36',\n",
       "  'rdrand',\n",
       "  'rdrnd',\n",
       "  'rdseed',\n",
       "  'rdtscp',\n",
       "  'rdwrfsgs',\n",
       "  'seglim64',\n",
       "  'sep',\n",
       "  'sgx',\n",
       "  'smap',\n",
       "  'smep',\n",
       "  'ss',\n",
       "  'ssbd',\n",
       "  'sse',\n",
       "  'sse2',\n",
       "  'sse3',\n",
       "  'sse4.1',\n",
       "  'sse4.2',\n",
       "  'sse4_1',\n",
       "  'sse4_2',\n",
       "  'ssse3',\n",
       "  'stibp',\n",
       "  'syscall',\n",
       "  'tm',\n",
       "  'tm2',\n",
       "  'tpr',\n",
       "  'tsc',\n",
       "  'tsc_thread_offset',\n",
       "  'tscdeadline',\n",
       "  'tsci',\n",
       "  'tsctmr',\n",
       "  'tsxfa',\n",
       "  'vme',\n",
       "  'vmx',\n",
       "  'x2apic',\n",
       "  'xd',\n",
       "  'xsave',\n",
       "  'xtpr'],\n",
       " 'l2_cache_line_size': 256,\n",
       " 'l2_cache_associativity': 6}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cpuinfo\n",
    "cpuinfo.get_cpu_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x86_64'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import platform \n",
    "platform.machine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "77ede9bdf46c5adcf6478d95ca4f2bb8e38b93f4a51397471ccd99549851b404"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
