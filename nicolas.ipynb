{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dataset_generator import dataset_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'python_version': '3.9.15.final.0 (64 bit)',\n",
       " 'cpuinfo_version': [9, 0, 0],\n",
       " 'cpuinfo_version_string': '9.0.0',\n",
       " 'arch': 'X86_64',\n",
       " 'bits': 64,\n",
       " 'count': 12,\n",
       " 'arch_string_raw': 'AMD64',\n",
       " 'vendor_id_raw': 'GenuineIntel',\n",
       " 'brand_raw': 'Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz',\n",
       " 'hz_advertised_friendly': '2.6000 GHz',\n",
       " 'hz_actual_friendly': '2.5920 GHz',\n",
       " 'hz_advertised': [2600000000, 0],\n",
       " 'hz_actual': [2592000000, 0],\n",
       " 'l2_cache_size': 1572864,\n",
       " 'stepping': 10,\n",
       " 'model': 158,\n",
       " 'family': 6,\n",
       " 'l3_cache_size': 12582912,\n",
       " 'flags': ['3dnow',\n",
       "  '3dnowprefetch',\n",
       "  'abm',\n",
       "  'acpi',\n",
       "  'adx',\n",
       "  'aes',\n",
       "  'apic',\n",
       "  'avx',\n",
       "  'avx2',\n",
       "  'bmi1',\n",
       "  'bmi2',\n",
       "  'clflush',\n",
       "  'clflushopt',\n",
       "  'cmov',\n",
       "  'cx16',\n",
       "  'cx8',\n",
       "  'de',\n",
       "  'dtes64',\n",
       "  'dts',\n",
       "  'erms',\n",
       "  'est',\n",
       "  'f16c',\n",
       "  'fma',\n",
       "  'fpu',\n",
       "  'fxsr',\n",
       "  'ht',\n",
       "  'hypervisor',\n",
       "  'ia64',\n",
       "  'invpcid',\n",
       "  'lahf_lm',\n",
       "  'mca',\n",
       "  'mce',\n",
       "  'mmx',\n",
       "  'monitor',\n",
       "  'movbe',\n",
       "  'mpx',\n",
       "  'msr',\n",
       "  'mtrr',\n",
       "  'osxsave',\n",
       "  'pae',\n",
       "  'pat',\n",
       "  'pbe',\n",
       "  'pcid',\n",
       "  'pclmulqdq',\n",
       "  'pdcm',\n",
       "  'pge',\n",
       "  'pni',\n",
       "  'popcnt',\n",
       "  'pse',\n",
       "  'pse36',\n",
       "  'rdrnd',\n",
       "  'rdseed',\n",
       "  'sep',\n",
       "  'serial',\n",
       "  'smap',\n",
       "  'smep',\n",
       "  'ss',\n",
       "  'sse',\n",
       "  'sse2',\n",
       "  'sse4_1',\n",
       "  'sse4_2',\n",
       "  'ssse3',\n",
       "  'tm',\n",
       "  'tm2',\n",
       "  'tsc',\n",
       "  'tscdeadline',\n",
       "  'vme',\n",
       "  'x2apic',\n",
       "  'xsave',\n",
       "  'xtpr'],\n",
       " 'l2_cache_line_size': 256,\n",
       " 'l2_cache_associativity': 6}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cpuinfo\n",
    "\n",
    "cpuinfo.get_cpu_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon ERROR @ 08:43:16] Need to first start the tracker\n",
      "  5%|▌         | 4/79 [05:42<2:42:37, 130.10s/it]c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      " 10%|█         | 8/79 [05:44<47:50, 40.43s/it]   c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=6.266e-03, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      " 11%|█▏        | 9/79 [05:46<38:16, 32.81s/it]c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LarsCV())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=4.658e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=4.512e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=3.316e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=2.849e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=2.175e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=4.620e-02, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.438e-02, with an active set of 15 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=8.743e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=8.323e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=5.100e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.818e-02, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.608e-02, with an active set of 15 regressors, and the smallest cholesky pivot element being 8.162e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=8.316e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 7.885e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=6.963e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 5.867e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=3.435e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 7.146e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LarsCV())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LarsCV())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LarsCV())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LarsCV())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LarsCV())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      " 14%|█▍        | 11/79 [07:00<36:06, 31.87s/it]c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.320e-04, tolerance: 3.938e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.518e-03, tolerance: 3.938e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.130e-02, tolerance: 9.984e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.022e-02, tolerance: 9.984e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.008e-02, tolerance: 9.994e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.048e-02, tolerance: 9.994e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.582e-02, tolerance: 9.984e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.006e-02, tolerance: 9.984e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.239e-02, tolerance: 9.984e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.151e-02, tolerance: 4.000e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      " 15%|█▌        | 12/79 [12:55<2:07:30, 114.18s/it]c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      " 16%|█▋        | 13/79 [12:55<1:32:09, 83.79s/it] c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsCV())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsCV())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsCV())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsCV())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsCV())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsCV())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      " 18%|█▊        | 14/79 [14:09<1:27:42, 80.97s/it]c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      " 24%|██▍       | 19/79 [14:18<23:10, 23.18s/it]  c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      " 32%|███▏      | 25/79 [14:19<07:22,  8.20s/it]c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuitCV())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuitCV())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuitCV())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuitCV())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuitCV())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\nico9\\anaconda3\\envs\\LauzHack\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuitCV())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "100%|██████████| 79/79 [33:55<00:00, 25.77s/it]   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(     CPU_count CPU_vendor_id  CPU_GHz core_architecture  memory_available_B  \\\n",
       " 0           12  GenuineIntel      2.6             AMD64          2471227392   \n",
       " 1           12  GenuineIntel      2.6             AMD64          2471227392   \n",
       " 2           12  GenuineIntel      2.6             AMD64          2471227392   \n",
       " 3           12  GenuineIntel      2.6             AMD64          2471227392   \n",
       " 4           12  GenuineIntel      2.6             AMD64          2471227392   \n",
       " ..         ...           ...      ...               ...                 ...   \n",
       " 173         12  GenuineIntel      2.6             AMD64          2471227392   \n",
       " 174         12  GenuineIntel      2.6             AMD64          2471227392   \n",
       " 175         12  GenuineIntel      2.6             AMD64          2471227392   \n",
       " 176         12  GenuineIntel      2.6             AMD64          2471227392   \n",
       " 177         12  GenuineIntel      2.6             AMD64          2471227392   \n",
       " \n",
       "      swap_free_B       os        model_name  nb_samples  nb_preds  \n",
       " 0     1947033600  Windows     ARDRegression          20        20  \n",
       " 1     1947033600  Windows     ARDRegression         500        20  \n",
       " 2     1947033600  Windows     ARDRegression         500       500  \n",
       " 3     1947033600  Windows     ARDRegression        2000        20  \n",
       " 4     1947033600  Windows     ARDRegression        2000       500  \n",
       " ..           ...      ...               ...         ...       ...  \n",
       " 173   1947033600  Windows  TweedieRegressor         500        20  \n",
       " 174   1947033600  Windows  TweedieRegressor         500       500  \n",
       " 175   1947033600  Windows  TweedieRegressor        2000        20  \n",
       " 176   1947033600  Windows  TweedieRegressor        2000       500  \n",
       " 177   1947033600  Windows  TweedieRegressor        2000      2000  \n",
       " \n",
       " [178 rows x 10 columns],\n",
       " [('GammaRegressor', sklearn.linear_model._glm.glm.GammaRegressor),\n",
       "  ('Hinge', sklearn.linear_model._sgd_fast.Hinge),\n",
       "  ('Huber', sklearn.linear_model._sgd_fast.Huber),\n",
       "  ('LassoLarsIC', sklearn.linear_model._least_angle.LassoLarsIC),\n",
       "  ('Log', sklearn.linear_model._sgd_fast.Log),\n",
       "  ('ModifiedHuber', sklearn.linear_model._sgd_fast.ModifiedHuber),\n",
       "  ('MultiTaskElasticNet',\n",
       "   sklearn.linear_model._coordinate_descent.MultiTaskElasticNet),\n",
       "  ('MultiTaskElasticNetCV',\n",
       "   sklearn.linear_model._coordinate_descent.MultiTaskElasticNetCV),\n",
       "  ('MultiTaskLasso', sklearn.linear_model._coordinate_descent.MultiTaskLasso),\n",
       "  ('MultiTaskLassoCV',\n",
       "   sklearn.linear_model._coordinate_descent.MultiTaskLassoCV),\n",
       "  ('RANSACRegressor', sklearn.linear_model._ransac.RANSACRegressor),\n",
       "  ('SquaredLoss', sklearn.linear_model._sgd_fast.SquaredLoss),\n",
       "  ('TheilSenRegressor', sklearn.linear_model._theil_sen.TheilSenRegressor),\n",
       "  ('__all__',\n",
       "   ['ARDRegression',\n",
       "    'BayesianRidge',\n",
       "    'ElasticNet',\n",
       "    'ElasticNetCV',\n",
       "    'Hinge',\n",
       "    'Huber',\n",
       "    'HuberRegressor',\n",
       "    'Lars',\n",
       "    'LarsCV',\n",
       "    'Lasso',\n",
       "    'LassoCV',\n",
       "    'LassoLars',\n",
       "    'LassoLarsCV',\n",
       "    'LassoLarsIC',\n",
       "    'LinearRegression',\n",
       "    'Log',\n",
       "    'LogisticRegression',\n",
       "    'LogisticRegressionCV',\n",
       "    'ModifiedHuber',\n",
       "    'MultiTaskElasticNet',\n",
       "    'MultiTaskElasticNetCV',\n",
       "    'MultiTaskLasso',\n",
       "    'MultiTaskLassoCV',\n",
       "    'OrthogonalMatchingPursuit',\n",
       "    'OrthogonalMatchingPursuitCV',\n",
       "    'PassiveAggressiveClassifier',\n",
       "    'PassiveAggressiveRegressor',\n",
       "    'Perceptron',\n",
       "    'QuantileRegressor',\n",
       "    'Ridge',\n",
       "    'RidgeCV',\n",
       "    'RidgeClassifier',\n",
       "    'RidgeClassifierCV',\n",
       "    'SGDClassifier',\n",
       "    'SGDRegressor',\n",
       "    'SGDOneClassSVM',\n",
       "    'SquaredLoss',\n",
       "    'TheilSenRegressor',\n",
       "    'enet_path',\n",
       "    'lars_path',\n",
       "    'lars_path_gram',\n",
       "    'lasso_path',\n",
       "    'orthogonal_mp',\n",
       "    'orthogonal_mp_gram',\n",
       "    'ridge_regression',\n",
       "    'RANSACRegressor',\n",
       "    'PoissonRegressor',\n",
       "    'GammaRegressor',\n",
       "    'TweedieRegressor']),\n",
       "  ('__builtins__',\n",
       "   {'__name__': 'builtins',\n",
       "    '__doc__': \"Built-in functions, exceptions, and other objects.\\n\\nNoteworthy: None is the `nil' object; Ellipsis represents `...' in slices.\",\n",
       "    '__package__': '',\n",
       "    '__loader__': _frozen_importlib.BuiltinImporter,\n",
       "    '__spec__': ModuleSpec(name='builtins', loader=<class '_frozen_importlib.BuiltinImporter'>, origin='built-in'),\n",
       "    '__build_class__': <function __build_class__>,\n",
       "    '__import__': <function __import__>,\n",
       "    'abs': <function abs(x, /)>,\n",
       "    'all': <function all(iterable, /)>,\n",
       "    'any': <function any(iterable, /)>,\n",
       "    'ascii': <function ascii(obj, /)>,\n",
       "    'bin': <function bin(number, /)>,\n",
       "    'breakpoint': <function breakpoint>,\n",
       "    'callable': <function callable(obj, /)>,\n",
       "    'chr': <function chr(i, /)>,\n",
       "    'compile': <function compile(source, filename, mode, flags=0, dont_inherit=False, optimize=-1, *, _feature_version=-1)>,\n",
       "    'delattr': <function delattr(obj, name, /)>,\n",
       "    'dir': <function dir>,\n",
       "    'divmod': <function divmod(x, y, /)>,\n",
       "    'eval': <function eval(source, globals=None, locals=None, /)>,\n",
       "    'exec': <function exec(source, globals=None, locals=None, /)>,\n",
       "    'format': <function format(value, format_spec='', /)>,\n",
       "    'getattr': <function getattr>,\n",
       "    'globals': <function globals()>,\n",
       "    'hasattr': <function hasattr(obj, name, /)>,\n",
       "    'hash': <function hash(obj, /)>,\n",
       "    'hex': <function hex(number, /)>,\n",
       "    'id': <function id(obj, /)>,\n",
       "    'input': <bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x000001F99678C730>>,\n",
       "    'isinstance': <function isinstance(obj, class_or_tuple, /)>,\n",
       "    'issubclass': <function issubclass(cls, class_or_tuple, /)>,\n",
       "    'iter': <function iter>,\n",
       "    'len': <function len(obj, /)>,\n",
       "    'locals': <function locals()>,\n",
       "    'max': <function max>,\n",
       "    'min': <function min>,\n",
       "    'next': <function next>,\n",
       "    'oct': <function oct(number, /)>,\n",
       "    'ord': <function ord(c, /)>,\n",
       "    'pow': <function pow(base, exp, mod=None)>,\n",
       "    'print': <function print>,\n",
       "    'repr': <function repr(obj, /)>,\n",
       "    'round': <function round(number, ndigits=None)>,\n",
       "    'setattr': <function setattr(obj, name, value, /)>,\n",
       "    'sorted': <function sorted(iterable, /, *, key=None, reverse=False)>,\n",
       "    'sum': <function sum(iterable, /, start=0)>,\n",
       "    'vars': <function vars>,\n",
       "    'None': None,\n",
       "    'Ellipsis': Ellipsis,\n",
       "    'NotImplemented': NotImplemented,\n",
       "    'False': False,\n",
       "    'True': True,\n",
       "    'bool': bool,\n",
       "    'memoryview': memoryview,\n",
       "    'bytearray': bytearray,\n",
       "    'bytes': bytes,\n",
       "    'classmethod': classmethod,\n",
       "    'complex': complex,\n",
       "    'dict': dict,\n",
       "    'enumerate': enumerate,\n",
       "    'filter': filter,\n",
       "    'float': float,\n",
       "    'frozenset': frozenset,\n",
       "    'property': property,\n",
       "    'int': int,\n",
       "    'list': list,\n",
       "    'map': map,\n",
       "    'object': object,\n",
       "    'range': range,\n",
       "    'reversed': reversed,\n",
       "    'set': set,\n",
       "    'slice': slice,\n",
       "    'staticmethod': staticmethod,\n",
       "    'str': str,\n",
       "    'super': super,\n",
       "    'tuple': tuple,\n",
       "    'type': type,\n",
       "    'zip': zip,\n",
       "    '__debug__': True,\n",
       "    'BaseException': BaseException,\n",
       "    'Exception': Exception,\n",
       "    'TypeError': TypeError,\n",
       "    'StopAsyncIteration': StopAsyncIteration,\n",
       "    'StopIteration': StopIteration,\n",
       "    'GeneratorExit': GeneratorExit,\n",
       "    'SystemExit': SystemExit,\n",
       "    'KeyboardInterrupt': KeyboardInterrupt,\n",
       "    'ImportError': ImportError,\n",
       "    'ModuleNotFoundError': ModuleNotFoundError,\n",
       "    'OSError': OSError,\n",
       "    'EnvironmentError': OSError,\n",
       "    'IOError': OSError,\n",
       "    'WindowsError': OSError,\n",
       "    'EOFError': EOFError,\n",
       "    'RuntimeError': RuntimeError,\n",
       "    'RecursionError': RecursionError,\n",
       "    'NotImplementedError': NotImplementedError,\n",
       "    'NameError': NameError,\n",
       "    'UnboundLocalError': UnboundLocalError,\n",
       "    'AttributeError': AttributeError,\n",
       "    'SyntaxError': SyntaxError,\n",
       "    'IndentationError': IndentationError,\n",
       "    'TabError': TabError,\n",
       "    'LookupError': LookupError,\n",
       "    'IndexError': IndexError,\n",
       "    'KeyError': KeyError,\n",
       "    'ValueError': ValueError,\n",
       "    'UnicodeError': UnicodeError,\n",
       "    'UnicodeEncodeError': UnicodeEncodeError,\n",
       "    'UnicodeDecodeError': UnicodeDecodeError,\n",
       "    'UnicodeTranslateError': UnicodeTranslateError,\n",
       "    'AssertionError': AssertionError,\n",
       "    'ArithmeticError': ArithmeticError,\n",
       "    'FloatingPointError': FloatingPointError,\n",
       "    'OverflowError': OverflowError,\n",
       "    'ZeroDivisionError': ZeroDivisionError,\n",
       "    'SystemError': SystemError,\n",
       "    'ReferenceError': ReferenceError,\n",
       "    'MemoryError': MemoryError,\n",
       "    'BufferError': BufferError,\n",
       "    'Warning': Warning,\n",
       "    'UserWarning': UserWarning,\n",
       "    'DeprecationWarning': DeprecationWarning,\n",
       "    'PendingDeprecationWarning': PendingDeprecationWarning,\n",
       "    'SyntaxWarning': SyntaxWarning,\n",
       "    'RuntimeWarning': RuntimeWarning,\n",
       "    'FutureWarning': FutureWarning,\n",
       "    'ImportWarning': ImportWarning,\n",
       "    'UnicodeWarning': UnicodeWarning,\n",
       "    'BytesWarning': BytesWarning,\n",
       "    'ResourceWarning': ResourceWarning,\n",
       "    'ConnectionError': ConnectionError,\n",
       "    'BlockingIOError': BlockingIOError,\n",
       "    'BrokenPipeError': BrokenPipeError,\n",
       "    'ChildProcessError': ChildProcessError,\n",
       "    'ConnectionAbortedError': ConnectionAbortedError,\n",
       "    'ConnectionRefusedError': ConnectionRefusedError,\n",
       "    'ConnectionResetError': ConnectionResetError,\n",
       "    'FileExistsError': FileExistsError,\n",
       "    'FileNotFoundError': FileNotFoundError,\n",
       "    'IsADirectoryError': IsADirectoryError,\n",
       "    'NotADirectoryError': NotADirectoryError,\n",
       "    'InterruptedError': InterruptedError,\n",
       "    'PermissionError': PermissionError,\n",
       "    'ProcessLookupError': ProcessLookupError,\n",
       "    'TimeoutError': TimeoutError,\n",
       "    'open': <function io.open(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)>,\n",
       "    'copyright': Copyright (c) 2001-2022 Python Software Foundation.\n",
       "    All Rights Reserved.\n",
       "    \n",
       "    Copyright (c) 2000 BeOpen.com.\n",
       "    All Rights Reserved.\n",
       "    \n",
       "    Copyright (c) 1995-2001 Corporation for National Research Initiatives.\n",
       "    All Rights Reserved.\n",
       "    \n",
       "    Copyright (c) 1991-1995 Stichting Mathematisch Centrum, Amsterdam.\n",
       "    All Rights Reserved.,\n",
       "    'credits':     Thanks to CWI, CNRI, BeOpen.com, Zope Corporation and a cast of thousands\n",
       "        for supporting Python development.  See www.python.org for more information.,\n",
       "    'license': Type license() to see the full license text,\n",
       "    'help': Type help() for interactive help, or help(object) for help about object.,\n",
       "    'execfile': <function _pydev_imps._pydev_execfile.execfile(file, glob=None, loc=None)>,\n",
       "    'runfile': <function _pydev_bundle.pydev_umd.runfile(filename, args=None, wdir=None, namespace=None)>,\n",
       "    '__IPYTHON__': True,\n",
       "    'display': <function IPython.core.display_functions.display(*objs, include=None, exclude=None, metadata=None, transient=None, display_id=None, raw=False, clear=False, **kwargs)>,\n",
       "    '__pybind11_internals_v4_mingw_libstdcpp_cxxabi1014__': <capsule object NULL at 0x000001F9AFE37DE0>,\n",
       "    'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x000001F99678CD00>>}),\n",
       "  ('__cached__',\n",
       "   'c:\\\\Users\\\\nico9\\\\anaconda3\\\\envs\\\\LauzHack\\\\lib\\\\site-packages\\\\sklearn\\\\linear_model\\\\__pycache__\\\\__init__.cpython-39.pyc'),\n",
       "  ('__doc__',\n",
       "   '\\nThe :mod:`sklearn.linear_model` module implements a variety of linear models.\\n'),\n",
       "  ('__file__',\n",
       "   'c:\\\\Users\\\\nico9\\\\anaconda3\\\\envs\\\\LauzHack\\\\lib\\\\site-packages\\\\sklearn\\\\linear_model\\\\__init__.py'),\n",
       "  ('__loader__',\n",
       "   <_frozen_importlib_external.SourceFileLoader at 0x1f99938ec10>),\n",
       "  ('__name__', 'sklearn.linear_model'),\n",
       "  ('__package__', 'sklearn.linear_model'),\n",
       "  ('__path__',\n",
       "   ['c:\\\\Users\\\\nico9\\\\anaconda3\\\\envs\\\\LauzHack\\\\lib\\\\site-packages\\\\sklearn\\\\linear_model']),\n",
       "  ('__spec__',\n",
       "   ModuleSpec(name='sklearn.linear_model', loader=<_frozen_importlib_external.SourceFileLoader object at 0x000001F99938EC10>, origin='c:\\\\Users\\\\nico9\\\\anaconda3\\\\envs\\\\LauzHack\\\\lib\\\\site-packages\\\\sklearn\\\\linear_model\\\\__init__.py', submodule_search_locations=['c:\\\\Users\\\\nico9\\\\anaconda3\\\\envs\\\\LauzHack\\\\lib\\\\site-packages\\\\sklearn\\\\linear_model'])),\n",
       "  ('_base',\n",
       "   <module 'sklearn.linear_model._base' from 'c:\\\\Users\\\\nico9\\\\anaconda3\\\\envs\\\\LauzHack\\\\lib\\\\site-packages\\\\sklearn\\\\linear_model\\\\_base.py'>),\n",
       "  ('_bayes',\n",
       "   <module 'sklearn.linear_model._bayes' from 'c:\\\\Users\\\\nico9\\\\anaconda3\\\\envs\\\\LauzHack\\\\lib\\\\site-packages\\\\sklearn\\\\linear_model\\\\_bayes.py'>),\n",
       "  ('_cd_fast',\n",
       "   <module 'sklearn.linear_model._cd_fast' from 'c:\\\\Users\\\\nico9\\\\anaconda3\\\\envs\\\\LauzHack\\\\lib\\\\site-packages\\\\sklearn\\\\linear_model\\\\_cd_fast.cp39-win_amd64.pyd'>),\n",
       "  ('_coordinate_descent',\n",
       "   <module 'sklearn.linear_model._coordinate_descent' from 'c:\\\\Users\\\\nico9\\\\anaconda3\\\\envs\\\\LauzHack\\\\lib\\\\site-packages\\\\sklearn\\\\linear_model\\\\_coordinate_descent.py'>),\n",
       "  ('_glm',\n",
       "   <module 'sklearn.linear_model._glm' from 'c:\\\\Users\\\\nico9\\\\anaconda3\\\\envs\\\\LauzHack\\\\lib\\\\site-packages\\\\sklearn\\\\linear_model\\\\_glm\\\\__init__.py'>),\n",
       "  ('_huber',\n",
       "   <module 'sklearn.linear_model._huber' from 'c:\\\\Users\\\\nico9\\\\anaconda3\\\\envs\\\\LauzHack\\\\lib\\\\site-packages\\\\sklearn\\\\linear_model\\\\_huber.py'>),\n",
       "  ('_least_angle',\n",
       "   <module 'sklearn.linear_model._least_angle' from 'c:\\\\Users\\\\nico9\\\\anaconda3\\\\envs\\\\LauzHack\\\\lib\\\\site-packages\\\\sklearn\\\\linear_model\\\\_least_angle.py'>),\n",
       "  ('_linear_loss',\n",
       "   <module 'sklearn.linear_model._linear_loss' from 'c:\\\\Users\\\\nico9\\\\anaconda3\\\\envs\\\\LauzHack\\\\lib\\\\site-packages\\\\sklearn\\\\linear_model\\\\_linear_loss.py'>),\n",
       "  ('_logistic',\n",
       "   <module 'sklearn.linear_model._logistic' from 'c:\\\\Users\\\\nico9\\\\anaconda3\\\\envs\\\\LauzHack\\\\lib\\\\site-packages\\\\sklearn\\\\linear_model\\\\_logistic.py'>),\n",
       "  ('_omp',\n",
       "   <module 'sklearn.linear_model._omp' from 'c:\\\\Users\\\\nico9\\\\anaconda3\\\\envs\\\\LauzHack\\\\lib\\\\site-packages\\\\sklearn\\\\linear_model\\\\_omp.py'>),\n",
       "  ('_passive_aggressive',\n",
       "   <module 'sklearn.linear_model._passive_aggressive' from 'c:\\\\Users\\\\nico9\\\\anaconda3\\\\envs\\\\LauzHack\\\\lib\\\\site-packages\\\\sklearn\\\\linear_model\\\\_passive_aggressive.py'>),\n",
       "  ('_perceptron',\n",
       "   <module 'sklearn.linear_model._perceptron' from 'c:\\\\Users\\\\nico9\\\\anaconda3\\\\envs\\\\LauzHack\\\\lib\\\\site-packages\\\\sklearn\\\\linear_model\\\\_perceptron.py'>),\n",
       "  ('_quantile',\n",
       "   <module 'sklearn.linear_model._quantile' from 'c:\\\\Users\\\\nico9\\\\anaconda3\\\\envs\\\\LauzHack\\\\lib\\\\site-packages\\\\sklearn\\\\linear_model\\\\_quantile.py'>),\n",
       "  ('_ransac',\n",
       "   <module 'sklearn.linear_model._ransac' from 'c:\\\\Users\\\\nico9\\\\anaconda3\\\\envs\\\\LauzHack\\\\lib\\\\site-packages\\\\sklearn\\\\linear_model\\\\_ransac.py'>),\n",
       "  ('_ridge',\n",
       "   <module 'sklearn.linear_model._ridge' from 'c:\\\\Users\\\\nico9\\\\anaconda3\\\\envs\\\\LauzHack\\\\lib\\\\site-packages\\\\sklearn\\\\linear_model\\\\_ridge.py'>),\n",
       "  ('_sag',\n",
       "   <module 'sklearn.linear_model._sag' from 'c:\\\\Users\\\\nico9\\\\anaconda3\\\\envs\\\\LauzHack\\\\lib\\\\site-packages\\\\sklearn\\\\linear_model\\\\_sag.py'>),\n",
       "  ('_sag_fast',\n",
       "   <module 'sklearn.linear_model._sag_fast' from 'c:\\\\Users\\\\nico9\\\\anaconda3\\\\envs\\\\LauzHack\\\\lib\\\\site-packages\\\\sklearn\\\\linear_model\\\\_sag_fast.cp39-win_amd64.pyd'>),\n",
       "  ('_sgd_fast',\n",
       "   <module 'sklearn.linear_model._sgd_fast' from 'c:\\\\Users\\\\nico9\\\\anaconda3\\\\envs\\\\LauzHack\\\\lib\\\\site-packages\\\\sklearn\\\\linear_model\\\\_sgd_fast.cp39-win_amd64.pyd'>),\n",
       "  ('_stochastic_gradient',\n",
       "   <module 'sklearn.linear_model._stochastic_gradient' from 'c:\\\\Users\\\\nico9\\\\anaconda3\\\\envs\\\\LauzHack\\\\lib\\\\site-packages\\\\sklearn\\\\linear_model\\\\_stochastic_gradient.py'>),\n",
       "  ('_theil_sen',\n",
       "   <module 'sklearn.linear_model._theil_sen' from 'c:\\\\Users\\\\nico9\\\\anaconda3\\\\envs\\\\LauzHack\\\\lib\\\\site-packages\\\\sklearn\\\\linear_model\\\\_theil_sen.py'>),\n",
       "  ('enet_path',\n",
       "   <function sklearn.linear_model._coordinate_descent.enet_path(X, y, *, l1_ratio=0.5, eps=0.001, n_alphas=100, alphas=None, precompute='auto', Xy=None, copy_X=True, coef_init=None, verbose=False, return_n_iter=False, positive=False, check_input=True, **params)>),\n",
       "  ('lars_path',\n",
       "   <function sklearn.linear_model._least_angle.lars_path(X, y, Xy=None, *, Gram=None, max_iter=500, alpha_min=0, method='lar', copy_X=True, eps=2.220446049250313e-16, copy_Gram=True, verbose=0, return_path=True, return_n_iter=False, positive=False)>),\n",
       "  ('lars_path_gram',\n",
       "   <function sklearn.linear_model._least_angle.lars_path_gram(Xy, Gram, *, n_samples, max_iter=500, alpha_min=0, method='lar', copy_X=True, eps=2.220446049250313e-16, copy_Gram=True, verbose=0, return_path=True, return_n_iter=False, positive=False)>),\n",
       "  ('lasso_path',\n",
       "   <function sklearn.linear_model._coordinate_descent.lasso_path(X, y, *, eps=0.001, n_alphas=100, alphas=None, precompute='auto', Xy=None, copy_X=True, coef_init=None, verbose=False, return_n_iter=False, positive=False, **params)>),\n",
       "  ('orthogonal_mp',\n",
       "   <function sklearn.linear_model._omp.orthogonal_mp(X, y, *, n_nonzero_coefs=None, tol=None, precompute=False, copy_X=True, return_path=False, return_n_iter=False)>),\n",
       "  ('orthogonal_mp_gram',\n",
       "   <function sklearn.linear_model._omp.orthogonal_mp_gram(Gram, Xy, *, n_nonzero_coefs=None, tol=None, norms_squared=None, copy_Gram=True, copy_Xy=True, return_path=False, return_n_iter=False)>),\n",
       "  ('ridge_regression',\n",
       "   <function sklearn.linear_model._ridge.ridge_regression(X, y, alpha, *, sample_weight=None, solver='auto', max_iter=None, tol=0.001, verbose=0, positive=False, random_state=None, return_n_iter=False, return_intercept=False, check_input=True)>)])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Model_features08-12-18.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('LauzHack')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4ca27458cc1d390750e5423ef1960079992d7b60cb8352775fdb8e63e4432f84"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
